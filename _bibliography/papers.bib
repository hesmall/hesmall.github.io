
@article{tuckute_frontal_2022,
	title = {Frontal language areas do not emerge in the absence of temporal language areas: {A} case study of an individual born without a left temporal lobe},
	volume = {169},
	copyright = {All rights reserved},
	issn = {1873-3514},
	shorttitle = {Frontal language areas do not emerge in the absence of temporal language areas},
	doi = {10.1016/j.neuropsychologia.2022.108184},
	abstract = {Language processing relies on a left-lateralized fronto-temporal brain network. How this network emerges ontogenetically remains debated. We asked whether frontal language areas emerge in the absence of temporal language areas through a 'deep-data' investigation of an individual (EG) born without her left temporal lobe. Using fMRI methods that have been validated to elicit reliable individual-level responses, we find that-as expected for early left-hemisphere damage-EG has a fully functional language network in her right hemisphere (comparable to the LH network in n = 145 controls) and intact linguistic abilities. However, we detect no response to language in EG's left frontal lobe (replicated across two sessions, 3 years apart). Another network-the multiple demand network-is robustly present in frontal lobes bilaterally, suggesting that EG's left frontal cortex can support non-linguistic cognition. The existence of temporal language areas therefore appears to be a prerequisite for the emergence of the frontal language areas.},
	language = {eng},
	journal = {Neuropsychologia},
	author = {Tuckute, Greta and Paunov, Alexander and Kean, Hope and Small, Hannah and Mineroff, Zachary and Blank, Idan and Fedorenko, Evelina},
	month = may,
	year = {2022},
	pmid = {35183561},
	keywords = {Brain Mapping, Case study, Female, Frontal Lobe, Functional Laterality, Humans, Language, Language development, Magnetic Resonance Imaging, Neuroimaging, notion, Plasticity, Temporal Lobe},
	pages = {108184},
	pdf = {tuckute_et_al_2022.pdf}
}

@article{hu_precision_2022,
	title = {Precision {fMRI} reveals that the language-selective network supports both phrase-structure building and lexical access during language production},
	copyright = {All rights reserved},
	issn = {1047-3211, 1460-2199},
	url = {https://academic.oup.com/cercor/advance-article/doi/10.1093/cercor/bhac350/6706753},
	doi = {10.1093/cercor/bhac350},
	abstract = {Abstract
            A fronto-temporal brain network has long been implicated in language comprehension. However, this network’s role in language production remains debated. In particular, it remains unclear whether all or only some language regions contribute to production, and which aspects of production these regions support. Across 3 functional magnetic resonance imaging experiments that rely on robust individual-subject analyses, we characterize the language network’s response to high-level production demands. We report 3 novel results. First, sentence production, spoken or typed, elicits a strong response throughout the language network. Second, the language network responds to both phrase-structure building and lexical access demands, although the response to phrase-structure building is stronger and more spatially extensive, present in every language region. Finally, contra some proposals, we find no evidence of brain regions—within or outside the language network—that selectively support phrase-structure building in production relative to comprehension. Instead, all language regions respond more strongly during production than comprehension, suggesting that production incurs a greater cost for the language network. Together, these results align with the idea that language comprehension and production draw on the same knowledge representations, which are stored in a distributed manner within the language-selective network and are used to both interpret and generate linguistic utterances.},
	language = {en},
	urldate = {2022-10-04},
	journal = {Cerebral Cortex},
	author = {Hu, Jennifer and Small, Hannah and Kean, Hope and Takahashi, Atsushi and Zekelman, Leo and Kleinman, Daniel and Ryan, Elizabeth and Nieto-Castañón, Alfonso and Ferreira, Victor and Fedorenko, Evelina},
	month = sep,
	year = {2022},
	pages = {1--21},
	pdf = {husmall_et_al_2023.pdf}
}

@article{lipkin_probabilistic_2022,
	title = {Probabilistic atlas for the language network based on precision {fMRI} data from >800 individuals},
	volume = {9},
	copyright = {2022 The Author(s)},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/s41597-022-01645-3},
	doi = {10.1038/s41597-022-01645-3},
	abstract = {Two analytic traditions characterize fMRI language research. One relies on averaging activations across individuals. This approach has limitations: because of inter-individual variability in the locations of language areas, any given voxel/vertex in a common brain space is part of the language network in some individuals but in others, may belong to a distinct network. An alternative approach relies on identifying language areas in each individual using a functional ‘localizer’. Because of its greater sensitivity, functional resolution, and interpretability, functional localization is gaining popularity, but it is not always feasible, and cannot be applied retroactively to past studies. To bridge these disjoint approaches, we created a probabilistic functional atlas using fMRI data for an extensively validated language localizer in 806 individuals. This atlas enables estimating the probability that any given location in a common space belongs to the language network, and thus can help interpret group-level activation peaks and lesion locations, or select voxels/electrodes for analysis. More meaningful comparisons of findings across studies should increase robustness and replicability in language research.},
	language = {en},
	number = {1},
	urldate = {2022-10-04},
	journal = {Scientific Data},
	author = {Lipkin, Benjamin and Tuckute, Greta and Affourtit, Josef and Small, Hannah and Mineroff, Zachary and Kean, Hope and Jouravlev, Olessia and Rakocevic, Lara and Pritchett, Brianna and Siegelman, Matthew and Hoeflin, Caitlyn and Pongos, Alvincé and Blank, Idan A. and Struhl, Melissa Kline and Ivanova, Anna and Shannon, Steven and Sathe, Aalok and Hoffmann, Malte and Nieto-Castañón, Alfonso and Fedorenko, Evelina},
	month = aug,
	year = {2022},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Cognitive neuroscience, Language},
	pages = {529},
	pdf = {lipkin_et_al_2022.pdf}
}

@article{corbin-leftwich_xenopus_2018,
	title = {A {Xenopus} oocyte model system to study action potentials},
	volume = {150},
	copyright = {All rights reserved},
	issn = {0022-1295, 1540-7748},
	url = {https://rupress.org/jgp/article/150/11/1583/120646/A-Xenopus-oocyte-model-system-to-study-action},
	doi = {10.1085/jgp.201812146},
	abstract = {Action potentials (APs) are the functional units of fast electrical signaling in excitable cells. The upstroke and downstroke of an AP is generated by the competing and asynchronous action of Na+- and K+-selective voltage-gated conductances. Although a mixture of voltage-gated channels has been long recognized to contribute to the generation and temporal characteristics of the AP, understanding how each of these proteins function and are regulated during electrical signaling remains the subject of intense research. AP properties vary among different cellular types because of the expression diversity, subcellular location, and modulation of ion channels. These complexities, in addition to the functional coupling of these proteins by membrane potential, make it challenging to understand the roles of different channels in initiating and “temporally shaping” the AP. Here, to address this problem, we focus our efforts on finding conditions that allow reliable AP recordings from Xenopus laevis oocytes coexpressing Na+ and K+ channels. As a proof of principle, we show how the expression of a variety of K+ channel subtypes can modulate excitability in this minimal model system. This approach raises the prospect of studies on the modulation of APs by pharmacological or biological means with a controlled background of Na+ and K+ channel expression.},
	language = {en},
	number = {11},
	urldate = {2022-10-04},
	journal = {Journal of General Physiology},
	author = {Corbin-Leftwich, Aaron and Small, Hannah E. and Robinson, Helen H. and Villalba-Galea, Carlos A. and Boland, Linda M.},
	month = nov,
	year = {2018},
	pages = {1583--1593},
	pdf = {corbin_leftwich_et_al_2018.pdf}
}

@misc{ozernov-palchik_precision_2024,
	title = {Precision {fMRI} reveals that the language network exhibits adult-like left-hemispheric lateralization by 4 years of age},
	copyright = {© 2024, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2024.05.15.594172v2},
	doi = {10.1101/2024.05.15.594172},
	abstract = {Left hemisphere damage in adulthood often leads to linguistic deficits, but many cases of early damage leave linguistic processing preserved, and a functional language system can develop in the right hemisphere. To explain this early apparent equipotentiality of the two hemispheres for language, some have proposed that the language system is bilateral during early development and only becomes left-lateralized with age. We examined language lateralization using functional magnetic resonance imaging with two large pediatric cohorts (total n=273 children ages 4-16; n=107 adults). Strong, adult-level left-hemispheric lateralization (in activation volume and response magnitude) was evident by age 4. Thus, although the right hemisphere can take over language function in some cases of early brain damage, and although some features of the language system do show protracted development (magnitude of language response and strength of inter-regional correlations in the language network), the left-hemisphere bias for language is robustly present by 4 years of age. These results call for alternative accounts of early equipotentiality of the two hemispheres for language.
Significance Statement Language is the most canonical function that shows a strong hemispheric asymmetry in adult brains. However, whether the language system is already lateralized to the left hemisphere early in development has long been debated, given that early left-hemisphere damage often leaves language processing unimpaired. We examined the developmental trajectory of language lateralization in two large-scale pediatric datasets using robust individual-subject fMRI approaches. We found that the language system exhibits adult-like left-hemispheric lateralization by age 4, although other aspects of the neural infrastructure for language show a clear change between age 4 and late childhood. These findings challengethe claim that the language system is bilateral during early development and call for alternative accounts of early hemispheric equipotentiality for language.},
	language = {en},
	urldate = {2024-10-29},
	publisher = {bioRxiv},
	author = {Ozernov-Palchik, Ola and O’Brien, Amanda M. and Lee, Elizabeth Jiachen and Richardson, Hilary and Romeo, Rachel and Lipkin, Benjamin and Small, Hannah and Capella, Jimmy and Nieto-Castañón, Alfonso and Saxe, Rebecca and Gabrieli, John D. E. and Fedorenko, Evelina},
	month = jun,
	year = {2024},
	note = {Pages: 2024.05.15.594172
Section: New Results},
	keywords = {notion},
	pdf = {}
}

@inproceedings{small_vision_2024,
	series = {Proceedings of {Machine} {Learning} {Research}},
	title = {Vision and language representations in multimodal {AI} models and human social brain regions during natural movie viewing},
	volume = {285},
	copyright = {All rights reserved},
	url = {https://proceedings.mlr.press/v285/small24a.html},
	abstract = {Recent work in NeuroAI suggests that representations in modern AI vision and language models are highly aligned with each other and human visual cortex. In addition, training AI vision models on language-aligned tasks (e.g., CLIP-style models) improves their match to visual cortex, particularly in regions involved in social perception, suggesting these brain regions may be similarly "language aligned". This prior work has primarily investigated only static stimuli without language, but in our daily lives, we experience the dynamic visual world and communicate about it using language simultaneously. To understand the processing of vision and language during natural viewing, we fit an encoding model to predict voxel-wise responses to an audiovisual movie using visual representations from both purely visual and language-aligned vision transformer models and paired language transformers. We first find that in naturalistic settings, there is remarkably low correlation between representations in vision and language models and both predict social perceptual and language regions well. Next, we find that language-alignment does not improve a vision model embedding’s match to neural responses in social perceptual regions, despite these regions being well predicted by both vision and language embeddings. Preliminary analyses, however, suggest that vision-alignment does improve a language model’s ability to match neural responses in language regions during audiovisual processing. Our work demonstrates the importance of testing multimodal AI models in naturalistic settings and reveals differences between language alignment in modern AI models and the human brain.},
	booktitle = {Proceedings of {UniReps}: the {Second} {Edition} of the {Workshop} on {Unifying} {Representations} in {Neural} {Models}},
	publisher = {PMLR},
	author = {Small, Hannah and Masson, Haemy Lee and Mostofsky, Stewart and Isik, Leyla},
	editor = {Fumero, Marco and Domine, Clementine and Lähner, Zorah and Crisostomi, Donato and Moschella, Luca and Stachenfeld, Kimberly},
	month = dec,
	year = {2024},
	pages = {69--84},
	pdf = {small_et_al_2024.pdf}
}

@misc{small_ubiquitous_2025,
	title = {Ubiquitous cortical sensitivity to visual information during naturalistic, audiovisual movie viewing},
	url = {https://osf.io/b5p4n_v1},
	doi = {10.31234/osf.io/b5p4n_v1},
	abstract = {Both vision and language carry rich information useful for social understanding in the real world, yet the neural processing of these signals have been mostly studied separately. Even most prior work with naturalistic stimuli does not model the contributions of vision and language signals together. Here we combined established fMRI localizer experiments, which identify social interaction perception- and language-selective regions, with a fMRI movie-viewing paradigm in the same individual participants (n=34). To pinpoint how multi-modal signals contribute to movie responses, we densely labeled the movie using vision and language deep neural networks (DNNs) and use these to predict neural responses. We found that vision model (motion and image) embeddings of movie frames predict significant activity across the cortex, while language model (speech, word, and sentence) embeddings of the spoken language predict well only in portions of the STS. We find that the individually localized motion and social interaction regions are best explained by vision model embeddings. Language regions, on the other hand, are well predicted by speech, word, and sentence language model embeddings and, surprisingly, are as equally well predicted by vision model embeddings. In an analysis of the vision model’s layer-wise and unit-wise predictivity, we find that the most predictive model units in social interaction and language regions are distinct from those in lower-level motion regions. Exploratory analyses suggest that the most predictive vision model units in social interaction and language regions contain social-semantic information conveyed by vision. Together, these results suggest that high-level visual information drives neural responses across cortex, even in language-selective regions, with varying integration of spoken language information across the STS.},
	language = {en-us},
	urldate = {2025-09-24},
	publisher = {OSF},
	author = {Small, Hannah and Lee Masson, Haemy and Wodka, Ericka and Mostofsky, Stewart and Isik, Leyla},
	month = sep,
	year = {2025},
	keywords = {naturalistic fMRI, neural encoding, notion, social perception},
	pdf = {Small_et_al_2025_preprint.pdf}
}
